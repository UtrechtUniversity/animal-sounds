{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466b32fb-1d52-407d-8d03-148259fa0aa2",
   "metadata": {},
   "source": [
    "# Exploration of Sanaga set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4ac2d-50a0-4103-b599-40f27659709c",
   "metadata": {},
   "source": [
    "## Create overviews of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13cfd7-5732-45cb-b507-ba3c3db716bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "def read_files_vocalizations(raven_path):\n",
    "    os.chdir(raven_path)\n",
    "    recorder = []\n",
    "    num_vocalizations = []\n",
    "    filelist = []\n",
    "\n",
    "    for file in glob.glob('*.txt'):\n",
    "        matchObj=re.search(\"A[0-9]+\", file)\n",
    "        recorder.append(matchObj.group())\n",
    "        num_vocalizations.append(count_vocalizations(file, 'Chimpanzee'))\n",
    "        filelist.append(file)\n",
    "\n",
    "    d = {'file': filelist, 'recorder':recorder,'vocalizations':num_vocalizations}\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def get_folder_stats(path, recorder):\n",
    "    os.chdir(path + recorder + '/')\n",
    "    df = pd.DataFrame(glob.glob('*.WAV'))\n",
    "\n",
    "    df.columns = ['files']\n",
    "    df = df.sort_values('files', ignore_index=True)\n",
    "\n",
    "    startstr = str(list(df.iloc[0])[0][:-4])\n",
    "    endstr = str(list(df.iloc[-1])[0][:-4])\n",
    "\n",
    "    starttime=datetime.datetime.strptime(startstr, \"%Y%m%d_%H%M%S\")\n",
    "    endtime = datetime.datetime.strptime(endstr, \"%Y%m%d_%H%M%S\")\n",
    "    duration = endtime-starttime\n",
    "\n",
    "    return [recorder, starttime, endtime, duration]\n",
    "\n",
    "def list_folder_stats(path):\n",
    "    data = []\n",
    "    \n",
    "    for recorder in os.listdir(path):\n",
    "        data.append(get_folder_stats(path, recorder))\n",
    "    return pd.DataFrame(data, columns=['recorder', 'start', 'end', 'duration'])\n",
    "\n",
    "def count_vocalizations(file, species):\n",
    "    df = process_raven(file, species)\n",
    "    return df.shape[0]\n",
    "\n",
    "def process_raven(file, species):\n",
    "    df = pd.read_table(file)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.loc[(df['class'] == species)]\n",
    "    df = df.rename(columns={'begin path': 'begin_path', 'end path': 'end_path'})\n",
    "    df['begin_path'] = df['begin_path'].str.replace('.*\\\\\\\\','', regex=True)\n",
    "    df['begin_path'] = df['begin_path'].str.replace('\\.WAV','', regex=True)\n",
    "    df['end_path'] = df['end_path'].str.replace('.*\\\\\\\\','', regex=True)\n",
    "    df['end_path'] = df['end_path'].str.replace('\\.WAV','', regex=True)\n",
    "    df['start_time'] = df['file offset (s)']\n",
    "    df['end_time'] = (df['file offset (s)']\n",
    "                            + df['end time (s)'] - df['begin time (s)'])\n",
    "    df = df_file_to_timestamp(df)\n",
    "    return df\n",
    "\n",
    "def read_processed_csv(path, recorder):\n",
    "    df = pd.read_csv(path + recorder  + '.csv')\n",
    "    df[\"start_datetime\"] = pd.to_datetime(df[\"start_datetime\"])\n",
    "    df[\"end_datetime\"] = pd.to_datetime(df[\"end_datetime\"])\n",
    "    return df\n",
    "\n",
    "def df_file_to_timestamp(df):\n",
    "    df['timestamp_beginfile'] = pd.to_datetime(df['begin_path'], format=\"%Y%m%d_%H%M%S\")\n",
    "    df['timestamp_endfile'] = pd.to_datetime(df['end_path'], format=\"%Y%m%d_%H%M%S\")\n",
    "    df['delta_t'] = df['timestamp_endfile']-df['timestamp_beginfile']\n",
    "    return df\n",
    "\n",
    "def wav_list(base_wav_path, recorder):\n",
    "    wav_path = base_wav_path + recorder + '/'\n",
    "    filelist = sorted(os.listdir(wav_path))\n",
    "    filelist = list(filter(lambda k: 'WAV' in k, filelist))\n",
    "    filelist = [sub[ : -4] for sub in filelist]\n",
    "    return filelist\n",
    "\n",
    "def yoda_get(file, source, dest):\n",
    "    filepath = source + file\n",
    "    p = subprocess.Popen(['iget', filepath, dest])\n",
    "    p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52e3b6-7098-43c9-b754-937423a351e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "raven_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga/'\n",
    "#path = '/home/jelle/Repositories/animalsounds/data/sanaga/'\n",
    "\n",
    "df_overview = list_folder_stats(path)\n",
    "df_vocalizations = read_files_vocalizations(raven_path)\n",
    "df_summary = df_overview.merge(df_vocalizations, how='left', on='recorder')\n",
    "df_summary = df_summary.dropna()\n",
    "df_summary['vocalizations'] = df_summary['vocalizations'].astype(int)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdda54-117f-4d11-9d79-eebe48fc204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transects = {'recorder':['A6', 'A2', 'A22', 'A5', 'A11', 'A21', 'A1', 'A23', 'A3', 'A4', 'A38', 'A31', 'A26', 'A40'], \n",
    "             'transect':['Mintak', 'Mintak', 'Mintak', 'Mintak', 'Mintak', 'Jacky', 'Jacky', 'Jacky', 'Jacky', 'Jacky', 'Bikols', 'Bikols', 'Bikols', 'Bikols'],\n",
    "             'Distance':[0, 200, 400, 600, 800, 0, 200, 400, 600, 800, 0, 200, 400, 600]}\n",
    "df_transects = pd.DataFrame(transects)\n",
    "df_transects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d3a8c-0424-4c99-a4b6-1345bbfaee7e",
   "metadata": {},
   "source": [
    "# Process raven files and save csv files of processed data\n",
    "Output will be a csv file per folder with filenames (.WAV) and respective timestamps of start and end time per vocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706804e-47f2-428c-8823-2ba4af69a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raven_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c75285-94ec-4565-8415-452e50f20b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = raven_path + '20210218_153318.Table.1.selections A38_JZ.txt'\n",
    "species = 'Chimpanzee'\n",
    "num_vocal = count_vocalizations(file, species)\n",
    "num_vocal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49341143-bc36-412b-8e69-e193f90f0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# Create file list\n",
    "def fix_multifile(df_out, filelist, wav_path):\n",
    "    row_i = list(df_out[(df_out['begin_path']\n",
    "                         != df_out['end_path'])].index)\n",
    "    for i in row_i:\n",
    "        last_index = df_out.index[-1]\n",
    "        filelength = librosa.get_duration(filename=wav_path + df_out.loc[i, 'begin_path'] + '.WAV')\n",
    "        \n",
    "        df = pd.DataFrame([[df_out.loc[i, 'begin_path'],\n",
    "                            df_out.loc[i, 'begin_path'],\n",
    "                            df_out.loc[i, 'start_time'],\n",
    "                            filelength],\n",
    "                           [df_out.loc[i, 'end_path'],\n",
    "                            df_out.loc[i, 'end_path'],\n",
    "                            0.0,\n",
    "                            df_out.loc[i, 'end_time']-filelength]],\n",
    "                          columns=['begin_path',\n",
    "                                   'end_path',\n",
    "                                   'start_time',\n",
    "                                   'end_time'])\n",
    "        df.index = [last_index+1, last_index+2]\n",
    "        df_out = df_out.append(df, ignore_index=False)\n",
    "\n",
    "        if df_out.loc[i, 'delta_t'].total_seconds() > 65:\n",
    "            for j in range(filelist.index(df_out.loc[i, 'begin_path'])\n",
    "                           + 1, filelist.index(df_out.loc[i, 'end_path'])):\n",
    "               \n",
    "                last_index = df_out.index[-1]\n",
    "                df = pd.DataFrame([[filelist[j],\n",
    "                                    filelist[j],\n",
    "                                    0.0,\n",
    "                                    librosa.get_duration(filename=wav_path + filelist[j] + '.WAV')]],\n",
    "                                  columns=['begin_path',\n",
    "                                           'end_path',\n",
    "                                           'start_time',\n",
    "                                           'end_time'])\n",
    "                df.index = [last_index+1]\n",
    "            df_out = df_out.append(df, ignore_index=False)\n",
    "    return df_out.drop(row_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0af6a-3317-46df-b2b1-0a9646d6efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "def clean_up(df):\n",
    "    df = df.loc[:, ['begin_path', \n",
    "                    'start_time', \n",
    "                    'end_time']]\n",
    "    df = df.drop(df[df['end_time'] - df['start_time'] < 0.2].index)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index'])\n",
    "    df['start_datetime'] = pd.to_datetime(df['begin_path'], format=\"%Y%m%d_%H%M%S\") + \\\n",
    "                           pd.to_timedelta(df['start_time'], unit='seconds')\n",
    "    df['end_datetime'] = pd.to_datetime(df['begin_path'], format=\"%Y%m%d_%H%M%S\") + \\\n",
    "                         pd.to_timedelta(df['end_time'], unit='seconds')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3af74e-020f-4a07-a05e-59bc16a52c27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_wav_path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "\n",
    "\n",
    "\n",
    "for index, f in enumerate(list(df_summary['file'])):\n",
    "    \n",
    "    file = raven_path + f\n",
    "    species = 'Chimpanzee'\n",
    "    recorder = re.search(\"A[0-9]+\", f).group(0)\n",
    "    \n",
    "    print(recorder)\n",
    "\n",
    "    filelist = wav_list(base_wav_path, recorder)\n",
    "    df = process_raven(file, species)\n",
    "    df = fix_multifile(df, filelist, wav_path)\n",
    "\n",
    "    df = clean_up(df)\n",
    "    df['recorder'] = recorder\n",
    "    df.to_csv('/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/' + recorder  + '.csv')\n",
    "    if index == 0:\n",
    "        df_all = df\n",
    "    else:\n",
    "        df_all.append(df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849676f2-68d6-492e-9118-a2482df0ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell above for a single recorder\n",
    "base_wav_path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "recorder = 'A38'\n",
    "wav_path = base_wav_path + recorder + '/'\n",
    "filelist = wav_list(base_wav_path, recorder)\n",
    "df = process_raven(file, species)\n",
    "df = fix_multifile(df, filelist, wav_path)\n",
    "\n",
    "df = clean_up(df)\n",
    "df['recorder'] = recorder\n",
    "df.to_csv('/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/' + recorder  + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543ceb5-472e-4ec3-9f3c-5f2d7dc6350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yodapath = '/nluu6p/home/research-zwerts/data/sanaga/A6/'\n",
    "destination = '/home/jelle/Repositories/animalsounds/data/sanaga/A6/'\n",
    "\n",
    "# create Unique list \n",
    "for file in list(df['begin_path'].unique()):\n",
    "    \n",
    "    print(file + '.WAV')\n",
    "    yoda_get(file + '.WAV', yodapath, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3500c-a8d9-48e8-bb38-6a3e6020a0d8",
   "metadata": {},
   "source": [
    "# Find vocalizations in A6 & A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980fbc7-f591-4a4f-b868-ec9780ca107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change order, first fix multifile, then timestamps\n",
    "\n",
    "## get 2 dataframes\n",
    "processed_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df6 = read_processed_csv(processed_path, recorder = 'A6')\n",
    "recorder = 'A22'\n",
    "df22 = read_processed_csv(processed_path, recorder = 'A22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327c308-0c39-4675-8e63-104c839adfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate fraction found based on timestamps\n",
    "### calculate df22 extent (create function cell 1)\n",
    "path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "recorder = 'A22'\n",
    "A22_overview = get_folder_stats(path, recorder)\n",
    "A22_overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c40294-0370-46b9-a75c-7741d6f84a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "### create df6 subset\n",
    "df6_subset = df6[(df6[\"start_datetime\"] > A22_overview[1]) & (df6[\"end_datetime\"] < A22_overview[2])]\n",
    "\n",
    "## sort dataframes\n",
    "df22 = df22.sort_values(by='start_datetime')\n",
    "df6_subset = df6_subset.sort_values(by='start_datetime')\n",
    "\n",
    "# WITHIN\n",
    "main = deque(list(df6_subset[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "dist = deque(list(df22[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "\n",
    "dist_start, dist_end = dist[0]\n",
    "\n",
    "dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080575d4-cf18-4c91-bf0f-3fefb49f84de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "display(df22)\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a43b1b-f13d-43a7-aa8c-4f73d3edc878",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hit_types = []\n",
    "new_time = 0.0\n",
    "within_time = 0.0\n",
    "not_found = 0.0\n",
    "margins = 0.0\n",
    "\n",
    "while(len(dist) > 0):\n",
    "    dist_start, dist_end = dist[0]\n",
    "    \n",
    "    while(len(main) > 0):\n",
    "        main_start, main_end = main[0]\n",
    "        if len(hit_types) > 0:\n",
    "            print(hit_types[-1])\n",
    "        if main_end < dist_start:\n",
    "            #            <----- dist ----->\n",
    "            # <-main->\n",
    "            # main vocalization did not reach a dist vocalization yet\n",
    "            # remove the current vocalization, move to the next\n",
    "            hit_types.append(('main before dist', new_time, main_start, \n",
    "                main_end, dist_start, dist_end))\n",
    "            \n",
    "            not_found += (main_end - main_start).total_seconds()\n",
    "            main.popleft()\n",
    "            # break the while loop to start next\n",
    "            \n",
    "        elif main_start <= dist_start and main_end >= dist_end:\n",
    "            #    <------- dist ------->       <--?dist?-->\n",
    "            # <---------- main ----------------------------->\n",
    "            # this is what we expect\n",
    "            within_time += (dist_end - dist_start).total_seconds()\n",
    "            margins += (dist_start - main_start).total_seconds()\n",
    "            \n",
    "            # However if there is another distant inside \n",
    "            # the main vocalization we need to account for this (MAYBE NOT NEEDED IF WE JUST NEED WITHIN TIME)\n",
    "            if len(dist) > 1:\n",
    "                if dist[1][0] < main_end:\n",
    "                    print(\"TWO distant contained\")\n",
    "                    margins += (main_end - dist_end).total_seconds()\n",
    "                    if dist[2][0] < main_end:\n",
    "                        print(\"CHAOS\")\n",
    "                        \n",
    "                    if main_end <= dist[1][1]:\n",
    "                        within_time += (main_end - dist_start).total_seconds()\n",
    "                        new_time += (dist_end - main_end).total_seconds()\n",
    "                    else:\n",
    "                        within_time += (dist_end - dist_start).total_seconds()\n",
    "                        margins += (main_end - dist_end).total_seconds()\n",
    "                    dist.popleft()\n",
    "                else:\n",
    "                    margins += (main_end - dist_end).total_seconds()\n",
    "            else:\n",
    "                margins += (main_end - dist_end).total_seconds()\n",
    "            \n",
    "            hit_types.append(('perfect', new_time, main_start, \n",
    "                            main_end, dist_start, dist_end))\n",
    "\n",
    "            dist.popleft()\n",
    "            break\n",
    "            \n",
    "        elif main_start <= dist_start and main_end > dist_start and main_end <= dist_end:\n",
    "            #          <----- dist ----->\n",
    "            # <-----main-------->\n",
    "            # this is bad\n",
    "            within_time += (main_end - dist_start).total_seconds()\n",
    "            new_time += (dist_end - main_end).total_seconds()\n",
    "            hit_types.append(('distant vocalization ends too late', new_time, main_start, \n",
    "                            main_end, dist_start, dist_end))\n",
    "            # remove the current negative interval\n",
    "            main.popleft()\n",
    "            # and break the loop to start with the next negative interval\n",
    "            \n",
    "        elif main_start >= dist_start and main_end <= dist_end:\n",
    "            #    <----- dist ----->\n",
    "            #         <-main-> <----main->\n",
    "            # this is bad\n",
    "            within_time += (main_end - main_start).total_seconds()\n",
    "            new_time += (main_start - dist_start).total_seconds()\n",
    "            new_time += (dist_end - main_end).total_seconds()\n",
    "            hit_types.append(('distant voc is longer on both sides', new_time, main_start, \n",
    "                            main_end, dist_start, dist_end))\n",
    "            # remove the current negative interval\n",
    "            main.popleft()\n",
    "            # and break the loop to start with the next dist interval (REMOVE this break???, yes we probably could, but we have to fix the new_time then, AND check the \"else\" part)\n",
    "            \n",
    "        elif main_start >= dist_start and main_start < dist_end and main_end >= dist_end:\n",
    "            #    <----- dist ----->\n",
    "            #                 <-main->\n",
    "            # this is bad\n",
    "            within_time += (dist_end - main_start).total_seconds()\n",
    "            new_time += (main_start - dist_start).total_seconds()\n",
    "            hit_types.append(('distant vocalization starts too soon',  new_time, main_start, \n",
    "                            main_end, dist_start, dist_end))\n",
    "            # remove the current negative interval\n",
    "            dist.popleft()\n",
    "            # and break the loop to start with the next negative interval\n",
    "            break\n",
    "        else:\n",
    "            #  <----- dist ----->\n",
    "            #                     <----main----->\n",
    "            # Not found before!\n",
    "            hit_types.append(('dist before main', new_time, main_start, \n",
    "                main_end, dist_start, dist_end))\n",
    "            new_time += (dist_end - dist_start).total_seconds()\n",
    "            dist.popleft()\n",
    "            break\n",
    "        # if there are no more positive intervals we can quit for this file\n",
    "        print(len(dist))\n",
    "        if len(dist) == 0:\n",
    "            main = [] \n",
    "        \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221149c-7136-4b7c-ae53-16025bd49d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_A6 = (df6_subset[\"end_datetime\"] - df6_subset[\"start_datetime\"]).sum().total_seconds()\n",
    "total_A22 = (df22[\"end_datetime\"] - df22[\"start_datetime\"]).sum().total_seconds()\n",
    "\n",
    "### Wat willen we vinden??\n",
    "## Hoeveel van de A6 vocalizaties zijn ook in A22 te horen? >>> Within time\n",
    "print(\"Within time = \" + str(within_time))\n",
    "\n",
    "## Hoeveel van de A6 vocalizaties zijn niet in A22 te horen? Total_A6 - within time\n",
    "print(\"Not found = \" + str(total_A6 - within_time))\n",
    "\n",
    "## Hoeveel van A22 is nieuw? Total_A22 - within time\n",
    "print(\"New found = \" + str(total_A22 - within_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cec2a7-93b9-46f9-bcba-4c467b8c8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df6_subset[\"duration [s]\"] = \n",
    "total_A6 = (df6_subset[\"end_datetime\"] - df6_subset[\"start_datetime\"]).sum().total_seconds()\n",
    "total_A22 = (df22[\"end_datetime\"] - df22[\"start_datetime\"]).sum().total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada01fee-7a0e-4293-97a3-8faeb63e39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(hit_types)):\n",
    "    if (hit_types[i-1][0] == 'main before dist') and hit_types[i][0] == 'dist before main':\n",
    "        print(str(i) + \"is not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07051aff-df00-467b-bf58-d4113ee78830",
   "metadata": {},
   "source": [
    "# Run for all recorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad70e1-4573-42c8-a420-be4b8ecf3c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def read_processed_csv(path, recorder):\n",
    "    df = pd.read_csv(path + recorder  + '.csv')\n",
    "    df[\"start_datetime\"] = pd.to_datetime(df[\"start_datetime\"])\n",
    "    df[\"end_datetime\"] = pd.to_datetime(df[\"end_datetime\"])\n",
    "    return df\n",
    "\n",
    "def overlap(main, dist):\n",
    "    hit_types = []\n",
    "    within_time = 0.0\n",
    "    dist_start, dist_end = dist[0]\n",
    "    \n",
    "    while(len(dist) > 0):\n",
    "        dist_start, dist_end = dist[0]\n",
    "\n",
    "        while(len(main) > 0):\n",
    "            main_start, main_end = main[0]\n",
    "            #if len(hit_types) > 0:\n",
    "                #print(hit_types[-1])\n",
    "            if main_end < dist_start:\n",
    "                #            <----- dist ----->\n",
    "                # <-main->\n",
    "                # main vocalization did not reach a dist vocalization yet\n",
    "                # remove the current vocalization, move to the next\n",
    "                hit_types.append(('main before dist', main_start, \n",
    "                    main_end, dist_start, dist_end))\n",
    "\n",
    "                main.popleft()\n",
    "                # break the while loop to start next\n",
    "\n",
    "            elif main_start <= dist_start and main_end >= dist_end:\n",
    "                #    <------- dist ------->       <--?dist?-->\n",
    "                # <---------- main ----------------------------->\n",
    "                # this is what we expect\n",
    "                within_time += (dist_end - dist_start).total_seconds()\n",
    "\n",
    "                # However if there is another distant inside \n",
    "                # the main vocalization we need to account for this (MAYBE NOT NEEDED IF WE JUST NEED WITHIN TIME)\n",
    "                if len(dist) > 1:\n",
    "                    if dist[1][0] < main_end:\n",
    "                        print(\"TWO distant contained\")\n",
    "                        if dist[2][0] < main_end:\n",
    "                            print(\"CHAOS\")\n",
    "\n",
    "                        if main_end <= dist[1][1]:\n",
    "                            within_time += (main_end - dist_start).total_seconds()\n",
    "                        else:\n",
    "                            within_time += (dist_end - dist_start).total_seconds()\n",
    "                        dist.popleft()\n",
    "                    #else:\n",
    "                        \n",
    "                #else:\n",
    "\n",
    "                hit_types.append(('perfect', main_start, \n",
    "                                main_end, dist_start, dist_end))\n",
    "\n",
    "                dist.popleft()\n",
    "                break\n",
    "\n",
    "            elif main_start <= dist_start and main_end > dist_start and main_end <= dist_end:\n",
    "                #          <----- dist ----->\n",
    "                # <-----main-------->\n",
    "                # this is bad\n",
    "                within_time += (main_end - dist_start).total_seconds()\n",
    "                hit_types.append(('distant vocalization ends too late', main_start, \n",
    "                                main_end, dist_start, dist_end))\n",
    "                # remove the current negative interval\n",
    "                main.popleft()\n",
    "                # and break the loop to start with the next negative interval\n",
    "\n",
    "            elif main_start >= dist_start and main_end <= dist_end:\n",
    "                #    <----- dist ----->\n",
    "                #         <-main-> <----main->\n",
    "                # this is bad\n",
    "                within_time += (main_end - main_start).total_seconds()\n",
    "                hit_types.append(('distant voc is longer on both sides', main_start, \n",
    "                                main_end, dist_start, dist_end))\n",
    "                # remove the current negative interval\n",
    "                main.popleft()\n",
    "                # and break the loop to start with the next dist interval (REMOVE this break???, yes we probably could, but we have to fix the new_time then, AND check the \"else\" part)\n",
    "\n",
    "            elif main_start >= dist_start and main_start < dist_end and main_end >= dist_end:\n",
    "                #    <----- dist ----->\n",
    "                #                 <-main->\n",
    "                # this is bad\n",
    "                within_time += (dist_end - main_start).total_seconds()\n",
    "                hit_types.append(('distant vocalization starts too soon', main_start, \n",
    "                                main_end, dist_start, dist_end))\n",
    "                # remove the current negative interval\n",
    "                dist.popleft()\n",
    "                # and break the loop to start with the next negative interval\n",
    "                break\n",
    "            else:\n",
    "                #  <----- dist ----->\n",
    "                #                     <----main----->\n",
    "                # Not found before!\n",
    "                hit_types.append(('dist before main', main_start, \n",
    "                    main_end, dist_start, dist_end))\n",
    "                dist.popleft()\n",
    "                break\n",
    "            # if there are no more positive intervals we can quit for this file\n",
    "            #print(len(dist))\n",
    "            if len(dist) == 0:\n",
    "                main = [] \n",
    "    return within_time, hit_types\n",
    "\n",
    "def calculate_totals(df_main, df_dist, within_time):\n",
    "    total_main = (df_main[\"end_datetime\"] - df_main[\"start_datetime\"]).sum().total_seconds()\n",
    "    totals = {'recorder': [rec_dist], \n",
    "             'total_main': total_main,\n",
    "             'within_sec': within_time,\n",
    "             'not_found': total_main - within_time,\n",
    "             'new_found': (df_dist[\"end_datetime\"] - df_dist[\"start_datetime\"]).sum().total_seconds()- within_time}\n",
    "\n",
    "    return pd.DataFrame(totals)\n",
    "\n",
    "\n",
    "processed_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/'\n",
    "path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "\n",
    "df_totals = pd.DataFrame(\n",
    "    columns=['recorder', 'total_main', 'within_sec', 'not_found', 'new_found'])\n",
    "\n",
    "\n",
    "for rec_main in ['A6', 'A21', 'A38']:\n",
    "    \n",
    "    df_main = read_processed_csv(processed_path, recorder = rec_main)\n",
    "    main_folder_stats = get_folder_stats(path, rec_main)\n",
    "    \n",
    "    if rec_main == 'A6':\n",
    "        transect = ['A22', 'A5']\n",
    "    elif rec_main == 'A21':\n",
    "        transect = ['A1', 'A3', 'A4']\n",
    "    else:\n",
    "        transect = ['A26']\n",
    "        \n",
    "    for rec_dist in transect:\n",
    "        \n",
    "        print(rec_dist)\n",
    "        \n",
    "        df_dist = read_processed_csv(processed_path, recorder = rec_dist)\n",
    "\n",
    "        ## Calculate fraction found based on timestamps\n",
    "\n",
    "        dist_folder_stats = get_folder_stats(path, rec_dist)\n",
    "\n",
    "        ### create df6 subset SUBSET VICE VERSA (dist longer than main)\n",
    "        df_main_subset = df_main[(df_main[\"start_datetime\"] > dist_folder_stats[1]) & (df_main[\"end_datetime\"] < dist_folder_stats[2])]\n",
    "        df_dist = df_dist[(df_dist[\"start_datetime\"] > main_folder_stats[1]) & (df_dist[\"end_datetime\"] < main_folder_stats[2])]\n",
    "\n",
    "        ## sort dataframes\n",
    "        df_dist = df_dist.sort_values(by='start_datetime')\n",
    "        df_main_subset = df_main_subset.sort_values(by='start_datetime')\n",
    "\n",
    "        main = deque(list(df_main_subset[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "        dist = deque(list(df_dist[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "        within_time, hit_types = overlap(main, dist)\n",
    "       \n",
    "        df = calculate_totals(df_main_subset, df_dist, within_time)\n",
    "        \n",
    "        df_totals = df_totals.append(df)\n",
    "#                      \n",
    "df_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ddad-7bfd-447d-87c2-e26711b306fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals['fraction_found'] = df_totals['within_sec']/df_totals['total_main'] \n",
    "\n",
    "test = pd.merge(df_summary, df_transects)\n",
    "df_final = pd.merge(test, df_totals, how='left')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45491ced-02d6-4104-8fca-ed8989b565e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# give a list to the marker argument\n",
    "sns.lmplot( x=\"Distance\", y=\"fraction_found\", data=df_final, fit_reg=False, hue='transect', legend=False, markers=[\"o\", \"x\", \"1\"], scatter_kws={\"s\": 120, \"alpha\": 0.5})\n",
    " \n",
    "# Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0cd19-cda3-4bcb-a9d3-b1407295161b",
   "metadata": {},
   "source": [
    "## create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810bae8-1510-4278-8210-a22b54d74e4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/'\n",
    "path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "rec_main = 'A21'\n",
    "rec_dist = 'A4'\n",
    "\n",
    "df_main = read_processed_csv(processed_path, recorder = rec_main)\n",
    "\n",
    "df_dist = read_processed_csv(processed_path, recorder = rec_dist)\n",
    "\n",
    "dist_folder_stats = get_folder_stats(path, rec_dist)\n",
    "\n",
    "df_main_subset = df_main[(df_main[\"start_datetime\"] > dist_folder_stats[1]) & (df_main[\"end_datetime\"] < dist_folder_stats[2])]\n",
    "base_wav_path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "\n",
    "filelist = pd.DataFrame(wav_list(base_wav_path, rec_dist), columns=['filename'])\n",
    "filelist['date_time'] = pd.to_datetime(filelist[\"filename\"], format=\"%Y%m%d_%H%M%S\")\n",
    "filelist.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f2b28-97d6-4b61-b76c-30a510ffb72a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wav_path = base_wav_path+rec_dist+'/'\n",
    "#filelengths = []\n",
    "#for idx, row in filelist.iterrows():\n",
    "#    print(row)\n",
    "#    filelengths.append(librosa.get_duration(filename=wav_path + row['filename'] + '.WAV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec0043-8d31-462f-8414-341dd59e2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filelist['filelength'] = filelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a441b-fe7a-4b27-9a97-e990e03988d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate main annotation in dist annotations\n",
    "\n",
    "df_new = pd.DataFrame(columns=[\"file\", \"offset\", \"duration\"])\n",
    "# create loop\n",
    "for idx, row in df_main_subset.iterrows():\n",
    "    print(row['start_datetime'])\n",
    "    \n",
    "    i = 0\n",
    "    while filelist.iloc[i+1, 1]< row['start_datetime']:\n",
    "         i += 1\n",
    "        \n",
    "    print(filelist.iloc[i,1])\n",
    "    start = (row['start_datetime'] - filelist.iloc[i,1]).total_seconds()\n",
    "    end_seconds = (row['end_datetime'] - filelist.iloc[i,1]).total_seconds()\n",
    "    print(start)\n",
    "            \n",
    "    file = wav_path + filelist.iloc[i,0] + '.WAV'\n",
    "    # check if file exists and is not corrupt (seconds to filestart < filelength)\n",
    "    if start < filelist.iloc[i,2] and os.path.getsize(file) > 0:\n",
    "        if end_seconds < filelist.iloc[i,2]:\n",
    "            # create and append annotation row\n",
    "            duration = end_seconds - start\n",
    "            newrow = \n",
    "        else:\n",
    "            \n",
    "    else:\n",
    "        #continue for loop\n",
    "        print(\"file error\")\n",
    "#4 check if end time is < filelength\n",
    "\n",
    "# if #4 is yes, check if next file exists\n",
    "# create annotation row\n",
    "# create and append rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43992a-8efd-4f6f-9979-1112251d66ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each main annotation check preceding filename\n",
    "import librosa\n",
    "import os\n",
    "#main = deque(list(df_main_subset[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "#dist = deque(list(df_dist[[\"start_datetime\", \"end_datetime\"]].itertuples(index=False, name=None)))\n",
    "base_wav_path = '/run/user/1000/gvfs/dav:host=science.data.uu.nl,ssl=true/research-zwerts/data/sanaga/'\n",
    "\n",
    "filelist = pd.DataFrame(wav_list(base_wav_path, rec_dist), columns=['filename'])\n",
    "filelist['date_time'] = pd.to_datetime(filelist[\"filename\"], format=\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "df_new = pd.DataFrame(columns=[\"file\", \"offset\", \"duration\"])\n",
    "df_main_emptylist = []\n",
    "\n",
    "for j in list(df_main_subset.index):\n",
    "    starttime = df_main_subset.loc[j,'start_datetime']\n",
    "    endtime = df_main_subset.loc[j,'end_datetime']\n",
    "\n",
    "    i=0\n",
    "    while i < len(filelist)-2:\n",
    "        \n",
    "        if (filelist.iloc[i, 1] <= starttime and filelist.iloc[i+1, 1] > starttime):\n",
    "            print(\"good\")\n",
    "            print(filelist.iloc[i, 0])\n",
    "            print(df_main_subset.loc[j, 'begin_path'])\n",
    "            \n",
    "            \n",
    "            # ADD check whether file exists (files\n",
    "\n",
    "            # Check file lenght\n",
    "            file_size = os.path.getsize(base_wav_path + rec_dist + '/' + filelist.iloc[i, 0] + '.WAV')\n",
    "            \n",
    "            if file_size == 0:\n",
    "                print(\"file is empty\")\n",
    "                # remove from prediction set\n",
    "                filelist = filelist.drop([filelist.index[i]])\n",
    "                df_main_emptylist.append(j)\n",
    "                break\n",
    "            else:\n",
    "                filelength = librosa.get_duration(filename=base_wav_path + rec_dist + '/' + filelist.iloc[i, 0] + '.WAV')\n",
    "                print(filelength)\n",
    "                # Calculate offset\n",
    "                offset = (starttime - filelist.iloc[i, 1]).total_seconds()\n",
    "                print(\"offset is \" + str(offset) + \" seconds\")\n",
    "                duration = (endtime - starttime).total_seconds()\n",
    "                if offset > filelength:\n",
    "                    print(\"recorder gap\")\n",
    "                    # What to do\n",
    "                    df_main_emptylist.append(j)\n",
    "                    break\n",
    "                    \n",
    "                if (offset+duration)>filelength:\n",
    "                    print(\"Multifile\")\n",
    "                    while (offset+duration)>filelength and duration > 0.0 and i<len(filelist)-1:\n",
    "                        ## Check if next file exists\n",
    "                        file_size = os.path.getsize(base_wav_path + rec_dist + '/' + filelist.iloc[i+1, 0] + '.WAV')\n",
    "                        if file_size == 0:\n",
    "                            print(\"second file in multifile annotation is empty\")\n",
    "                            # This part should be removed from df_main\n",
    "                            break\n",
    "                            \n",
    "                        duration_1 = filelength-offset\n",
    "\n",
    "                        df_new = df_new.append({\"file\": filelist.iloc[i, 0] + '.WAV',\n",
    "                                                \"offset\":  offset,\n",
    "                                                \"duration\": duration_1,\n",
    "                                                }, ignore_index=True)\n",
    "                        i+=1\n",
    "                        starttime_newfile = filelist.iloc[i,1]\n",
    "                        duration = (endtime - starttime_newfile).total_seconds()\n",
    "                        filelength = librosa.get_duration(filename=base_wav_path + rec_dist + '/' + filelist.iloc[i, 0] + '.WAV')\n",
    "                        offset=0.0\n",
    "                        \n",
    "\n",
    "                    df_new = df_new.append({\"file\": filelist.iloc[i, 0] + '.WAV',\n",
    "                                \"offset\":  offset,\n",
    "                                \"duration\": duration,\n",
    "                                }, ignore_index=True)\n",
    "                    # create row,update offset check again, how to deal with index?\n",
    "                else:\n",
    "                    df_new = df_new.append({\"file\": filelist.iloc[i, 0] + '.WAV',\n",
    "                                            \"offset\":  offset,\n",
    "                                            \"duration\": duration,\n",
    "                                            }, ignore_index=True)\n",
    "\n",
    "            break\n",
    "\n",
    "        i+=1\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099edf7-7eed-4790-a6cf-088c160de4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'A4'\n",
    "output_path = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_test/chimpanzee/'\n",
    "df_new.to_csv(output_path + folder + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f8f27-4153-491b-8f0d-80fdd758b63e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_test/chimpanzee/' + folder + '.csv')\n",
    "df.head()\n",
    "\n",
    "yodapath = '/nluu6p/home/research-zwerts/data/sanaga/' + folder + '/'\n",
    "destination = '/home/jelle/Repositories/animalsounds/data/sanaga/' + folder + '/'\n",
    "\n",
    "# create Unique list \n",
    "for file in list(df['file'].unique()):\n",
    "    \n",
    "    print(file)\n",
    "    yoda_get(file, yodapath, destination)\n",
    "    \n",
    "annotations_path = '/home/jelle/Repositories/animalsounds/data/sanaga/' + folder + '/'\n",
    "output_path = '/home/jelle/Repositories/animalsounds/data/sanaga_test/chimps/' + folder + '/'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Open\n",
    "    filepath = annotations_path + row['file']\n",
    "    y, sr = librosa.load(filepath, sr=48000,\n",
    "                             offset=row['offset'],\n",
    "                             duration=row['duration'])\n",
    "    outfile = (output_path + str(index) + '_sanaga_' + row['file'][0:-4] + '_' + str(row['offset']) + '.wav')\n",
    "    print(outfile)\n",
    "    sf.write(outfile, y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c59a9c-a137-4920-9d3d-c026c19f968d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "annotations_path = '/home/jelle/Repositories/animalsounds/data/sanaga/' + folder + '/'\n",
    "output_path = '/home/jelle/Repositories/animalsounds/data/sanaga_test/chimps/' + folder + '/'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Open\n",
    "    filepath = annotations_path + row['file']\n",
    "    y, sr = librosa.load(filepath, sr=48000,\n",
    "                             offset=row['offset'],\n",
    "                             duration=row['duration'])\n",
    "    outfile = (output_path + str(index) + '_sanaga_' + row['file'][0:-4] + '_' + str(row['offset']) + '.wav')\n",
    "    print(outfile)\n",
    "    sf.write(outfile, y, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77213b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Sanaga processed csv format (only run for main recorders)\n",
    "\n",
    "folder = 'A38'\n",
    "file = '/home/jelle/Repositories/animalsounds/data/raven_annotations/sanaga_processed/' + folder + '.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb190fde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yodapath = '/nluu6p/home/research-zwerts/data/sanaga/' + folder + '/'\n",
    "destination = '/home/jelle/Repositories/animalsounds/data/sanaga/' + folder + '/'\n",
    "\n",
    "# create Unique list \n",
    "for file in list(df['begin_path'].unique()):\n",
    "    \n",
    "    print(file)\n",
    "    yoda_get(file + '.WAV', yodapath, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403947bf-b146-4bdb-a014-47270a7c80f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "annotations_path = '/home/jelle/Repositories/animalsounds/data/sanaga/' + folder + '/'\n",
    "output_path = '/home/jelle/Repositories/animalsounds/data/sanaga_test/chimps/' + folder + '/'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Open\n",
    "    filepath = annotations_path + row['begin_path'] + '.WAV'\n",
    "    duration = row['end_time']-row['start_time']\n",
    "    y, sr = librosa.load(filepath, sr=48000,\n",
    "                             offset=row['start_time'],\n",
    "                             duration=duration)\n",
    "    outfile = (output_path + str(index) + '_sanaga_' + row['begin_path'] + '_' + str(row['start_time']) + '.wav')\n",
    "    print(outfile)\n",
    "    sf.write(outfile, y, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
